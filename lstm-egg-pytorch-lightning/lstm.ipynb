{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xzcKUiLzhn2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6cdcbb8a-2ee1-438e-e5a3-30dac7ffa5a4"
      },
      "source": [
        "! pip install pytorch-lightning --quiet\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "%cd ./drive/MyDrive/Colab\\ Notebooks/nn_assign4_lstm"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "[Errno 2] No such file or directory: './drive/MyDrive/Colab Notebooks/nn_assign4_lstm'\n",
            "/content/drive/MyDrive/Colab Notebooks/nn_assign4_lstm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbe45KL70x1U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "041fafd7-3d6c-467c-9964-8a9a696674a1"
      },
      "source": [
        "from util import *\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,RobustScaler\n",
        "log_dir = \"lightning_logs\"\n",
        "seed_everything(777)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 777\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IhPpB-eZclhb",
        "outputId": "dc3e4106-43be-4c97-e30b-de6713daa14b"
      },
      "source": [
        "def load_data(test=False, seed = 12345):\n",
        "    train_x = np.load('./Data/train_data.npy') # 11 ppl\n",
        "    train_y = np.load('./Data/train_label.npy')\n",
        "    test_x = np.load('./Data/test_data.npy') # 4 ppl\n",
        "    test_y = np.load('./Data/test_label.npy')\n",
        "    scaler = MinMaxScaler()\n",
        "    train_x = scaler.fit_transform(train_x)\n",
        "    test_x = scaler.transform(test_x)\n",
        "    if(test):\n",
        "        return test_x,test_y\n",
        "    else:\n",
        "       return train_x,train_y\n",
        "    \n",
        "x,y = load_data()\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "# x"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37367, 310)\n",
            "(37367,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk8gH3bjcoQV"
      },
      "source": [
        "# show data\n",
        "class SeedDataset(Dataset):\n",
        "    def __init__(self,window,test=False,):\n",
        "        self.data,self.target = load_data(test)\n",
        "        self.window = window\n",
        "        self.target = np.array(self.target,int)\n",
        "        index = np.where(self.target==-1)\n",
        "        self.target[index]=2 \n",
        "    def __len__(self):\n",
        "        return len(self.target) // self.window\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        idx = idx * self.window\n",
        "        data = torch.tensor(self.data[idx:idx+self.window], dtype=torch.float)\n",
        "        label_ls = np.bincount(self.target[idx:idx+self.window]).argmax()\n",
        "        \n",
        "        label = torch.tensor(label_ls,dtype=torch.long)\n",
        "        return data, label\n",
        "    \n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jRznJEtmdNop",
        "outputId": "dc4ecf8f-ca09-4938-dec2-ffe8ce3303c6"
      },
      "source": [
        "sdm = SeedDataset(window=10)\n",
        "print(f'training data {len(sdm)}')\n",
        "idx= 1000\n",
        "# np.unique(sdm.target)\n",
        "print(f'x shape:{sdm[idx][0].shape}')\n",
        "# print(f'y value:{sdm[idx][1]}')\n",
        "# np.unique([sdm[idx][1],sdm[idx+1][1],sdm[idx+20][1],sdm[idx+30][1],sdm[idx+1000][1],sdm[idx+5][1]])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data 3736\n",
            "x shape:torch.Size([10, 310])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mETCd0mD1Vyc"
      },
      "source": [
        "\n",
        "class SeedDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self,window=10,batch_size=32,shuffle=False):\n",
        "        super().__init__()\n",
        "        self.batch_size=batch_size\n",
        "        self.window = window\n",
        "        self.shuffle = shuffle\n",
        "    def setup(self,stage=None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            train_full = SeedDataset(self.window)\n",
        "            train, val = train_test_split(train_full,shuffle=self.shuffle)\n",
        "            self.train_set = train_full\n",
        "            # self.val_set = val\n",
        "        \n",
        "        if stage == 'test' or stage is None:\n",
        "            self.test_set = SeedDataset(self.window,test=True)\n",
        "        \n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set,batch_size=self.batch_size,shuffle=self.shuffle)\n",
        "\n",
        "    # def val_dataloader(self):\n",
        "    #     return DataLoader(self.val_set,batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set,batch_size=1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYrhG-OO57dW"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMQN2w4I2WSD"
      },
      "source": [
        "class LSTM(LightningModule):\n",
        "    def __init__(self,hidden_size = 100,window_size=10, lr=1e-3,batch_size=16):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.lstm = nn.LSTM(input_size= 310,\n",
        "                    hidden_size = self.hparams.hidden_size,\n",
        "                    num_layers = 1,\n",
        "                    batch_first=True,\n",
        "                    bidirectional=False)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.fc = nn.Linear(in_features = self.hparams.hidden_size, out_features=3)\n",
        "        self.target = None\n",
        "        self.pred = None\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x = 32,10,310 -> batch_size, seq_length, input_size\n",
        "        h0 = torch.zeros(1,x.size(0),self.hparams.hidden_size, device=self.device)\n",
        "        c0 = torch.zeros(1,x.size(0),self.hparams.hidden_size, device=self.device)\n",
        "       \n",
        "        # print(x.shape)\n",
        "        out, _ = self.lstm(x,(h0,c0)) # out: batch_size, seq_length, hidden_size\n",
        "        \n",
        "        out = out[:,-1,:]\n",
        "\n",
        "        return self.fc(out) \n",
        "\n",
        "    def training_step(self,batch,batch_idx):\n",
        "        loss = 0\n",
        "        x, label = batch\n",
        "        # y = torch.squeeze(label,0)\n",
        "   \n",
        "        # print(label.shape)\n",
        "        logits = self.forward(x)\n",
        "        loss += self.criterion(logits, label)\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        # print(predicted)\n",
        "        acc = accuracy(predicted,label)\n",
        "\n",
        "        self.log('train/loss', loss,on_step=False, on_epoch=True)\n",
        "        self.log('train/acc',acc, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # validation_step defined the train loop.\n",
        "        # It is independent of forward\n",
        "\n",
        "        x, class_label = batch\n",
        "        # print(x)\n",
        "        # classfication loss\n",
        "        logits = self.forward(x)\n",
        "        score, predicted = torch.max(logits, 1)\n",
        "        # print(f'predicted:{predicted.item()}, should be {class_label.item()}')\n",
        "        acc = accuracy(predicted,class_label)\n",
        "        \n",
        "        return {\"acc\":acc,\n",
        "                \"pred\":predicted,\n",
        "                \"label\":class_label}\n",
        "\n",
        "    def test_epoch_end(self,outputs):\n",
        "        test_acc = torch.mean(\n",
        "            torch.stack([x[\"acc\"] for x in outputs]))\n",
        "        self.test_acc=test_acc\n",
        "        self.log(\"hp_metric\",test_acc)\n",
        "        preds = torch.stack([x[\"pred\"] for x in outputs])\n",
        "        targets = torch.stack([x[\"label\"] for x in outputs])\n",
        "        self.target =targets\n",
        "        self.pred = preds\n",
        "        # self.learned_weights = list(self.parameters())\n",
        "        # print(classification_report(y_test, res, target_names=target_names))\n",
        "        # confusion_matrix = pl.metrics.functional.confusion_matrix(preds, targets, num_classes=10)\n",
        "        # df_cm = pd.DataFrame(confusion_matrix.to(\"cpu\").numpy(), index = range(10), columns=range(10))\n",
        "        # plt.figure(figsize = (10,7))\n",
        "        # fig_ = sns.heatmap(df_cm, annot=True, cmap='Spectral').get_figure()\n",
        "        # plt.close(fig_)\n",
        "        \n",
        "        # self.logger.experiment.add_figure(\"Confusion matrix\", fig_, self.current_epoch)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr,weight_decay=2e-5)\n",
        "                                    \n",
        "        return optimizer"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjDFzXZ649bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c9483558-cf71-4b1c-c5c2-5ad465b24b3b"
      },
      "source": [
        "# model_accuracy_lstm = list()\n",
        "def train_model(lr=1e-4,window = 10,batch_size=16,hidden_size=100):\n",
        "    logger = TensorBoardLogger(log_dir, name=\"lstm\")\n",
        "    trainer = Trainer(max_epochs=12, progress_bar_refresh_rate=0,\n",
        "                      fast_dev_run=False,\n",
        "                        logger= logger,\n",
        "                    # gpus=-1,\n",
        "                    weights_summary=None\n",
        "                    )\n",
        "    m = LSTM(lr=lr,hidden_size=hidden_size,window_size = window,batch_size=batch_size)\n",
        "    sdm = SeedDataModule(window=window,batch_size=batch_size,shuffle=False)\n",
        "    trainer.fit(m,sdm)\n",
        "    trainer.test(m,datamodule=sdm)\n",
        "    return m\n",
        "\n",
        "\n",
        "\n",
        "# train_model(window = 10,lr=1e-2,batch_size=16,hidden_size=100)\n",
        "# train_model(window = 10,lr=1e-3,batch_size=16,hidden_size=100)\n",
        "# train_model(window = 10,lr=1e-2,batch_size=16,hidden_size=100)\n",
        "# train_model(window = 10,lr=1e-2,batch_size=16,hidden_size=100)\n",
        "# train_model(window = 10,lr=1e-3,batch_size=32,hidden_size=100)\n",
        "# train_model(window = 10,lr=1e-4,batch_size=64,hidden_size=100)\n",
        "# train_model(window = 10,lr=1e-5,batch_size=10,hidden_size=128) #45%\n",
        "# train_model(window = 8,lr=1e-3,batch_size=10,hidden_size=128) #53%\n",
        "m = train_model(window = 50,lr=1e-3,batch_size=10,hidden_size=128) #54%\n",
        "# train_model(window = 40,lr=1e-3,batch_size=10,hidden_size=128) #42%\n",
        "# train_model(window = 30,lr=1e-3,batch_size=10,hidden_size=128) #51%\n",
        "# train_model(window = 20,lr=1e-3,batch_size=10,hidden_size=128) #51%\n",
        "# train_model(window = 70,lr=1e-3,batch_size=10,hidden_size=128) #44.8%\n",
        "# train_model(window = 80,lr=1e-3,batch_size=10,hidden_size=128) #42%\n",
        "\n",
        "window_ = [10,1]\n",
        "lr_ = [1e-3]\n",
        "batch_ = [1]\n",
        "# for window in window_:\n",
        "#     for lr in lr_:\n",
        "#         for batch in batch_:\n",
        "#             train_model(window = window,lr=lr,batch_size=batch,hidden_size=128)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'hp_metric': 0.5904058814048767}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yBu4XVYAlD25",
        "outputId": "95bdca52-7915-4836-bdb1-aeaf6de40766"
      },
      "source": [
        "target_names = [\"0\",\"1\",\"-1\"]\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(m.pred, m.target, target_names=target_names))\n",
        "# confusion_matrix = pl.metrics.functional.confusion_matrix(preds, targets, num_classes=10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.67      0.31        27\n",
            "           1       0.94      0.56      0.70       160\n",
            "          -1       0.60      0.62      0.61        84\n",
            "\n",
            "    accuracy                           0.59       271\n",
            "   macro avg       0.58      0.62      0.54       271\n",
            "weighted avg       0.76      0.59      0.64       271\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRKS9Fmm6IfN"
      },
      "source": [
        "# # !kill 287\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir lightning_logs/"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3PDXuz8HIM1"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}